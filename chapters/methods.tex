\chapter{Метод адаптации численных схем}
\label{chapter:methods} \index{Методы}

В прошлой главе был приведён краткий обзор существующих методов оценки устойчивости динамических систем и численных схем.
Введены основные элементы линейного и нелинейного анализа устойчивости.
Введено понятие жёсткости системы, разделённое в дальнейшем на классическую и нелинейную жёсткость.
Было показано, что с классической жёсткостью эффективно справляются A"=устойчивые и L"=устойчивые методы,
в том числе и экспоненциальные интеграторы, интегрирующие линейную часть системы точно.
Наконец, обозначена невозможность решения проблем нелинейной жёсткости в рамках линейной теории устойчивости.

Данная глава полностью посвящена разработке новых методов численного решения дифференциальных уравнений,
совмещающих преимущества устойчивых неявных схем и экспоненциальных интеграторов.
%потенциально способных показать более устойчивое поведение на нелинейно жёстких системах,
%оставаясь при этом устойчивыми и с точки зрения линейной жёсткости.
%В то же время, разрабатываемые методы должны устойчиво интегрировать линейно жёсткие системы.
Первый раздел посвящен общему подходу к построению новых методов численного интегрирования:
предлагается адаптивно варьировать коэффициенты существующих разностных схем
для достижения новых свойств при сохранении преимуществ исходного численного метода.
Во втором разделе демонстрируется применение разработанного подхода к нескольким выбранным задачам малой размерности.
Наконец, в третьем разделе предложенный подход применяется для получения нового семейства
экспоненциальных интеграторов в случае задач произвольной размерности.


\section{Общее описание метода}
\label{section:methods:description}

Суть предлагаемого метода заключается в подборе коэффициентов некоторой численной схемы
с целью получения более точного (в идеале, совпадающего с аналитическим) численного решения
для выбранного класса задач (например, для линейных или хорошо линеаризуемых динамических систем).

Формальное описание метода начнём с рассмотрения семейства динамических систем,
задаваемых уравнением $ \dot{\bvec{x}} = f(t, \bvec{x}) $,
где $ f \in \rhsfamily $, $ \bvec{x} \in \banachspace $, и $ \banachspace $~--- банахово.
Предполагаем, что для всех $ f \in \rhsfamily $ и $ \bvec{x}_0 \in \initialcond(f) $ решение соответствующей задачи Коши
на отрезке $ [0; T] $ существует и единственно:
\[
    \forall f \in \rhsfamily \quad \exists! \bvec{x}_f \colon [0; T] \times \initialcond(f) \to \banachspace: \qquad
    \begin{dcases}
        \frac{\partial \bvec{x}_f}{\partial t} = f(t, \bvec{x}_f) \\
        \bvec{x}_f(0; \bvec{x}_0) = \bvec{x}_0
    \end{dcases}
\]
Далее рассмотрим семейство методов численного интегрирования $ \nmfamily $.%
\footnote{На практике семейство обычно задаётся множеством параметров,
конкретные значения которых определяет конкретную численную схему
(например, таблица Бутчера параметризует методы Рунге-Кутты).}
Обозначим за $ \{ \bvec{x}_M^n(\bvec{x}_0) \}_{n=0}^{N} $ набор численных решений,
полученных на фиксированной сетке $ \{ t_n \}_{n=0}^N $ согласно методу $ M \in \nmfamily $.

Пусть $ \Phi $~--- функционал качества численного решения
(например, $ l_2 $-норма отклонения от точного решения на узлах сетки).
Тогда выберем из $ \nmfamily $ схему,
достигающую наименьшего значения функционала
для всех допустимых правых частей $ f $ и начальных условий $ \bvec{x}_0 \in \initialcond(f) $:

\begin{definition}
    \label{definition:adaptation_method:adapted_numerical_method}
    \emph{Адаптацией} семейства численных методов $ \nmfamily $ к семейству задач Коши
    $ \{ \dot{\bvec{x}} = f(t, \bvec{x}), \; \bvec{x}(0) = \bvec{x}_0 \mid f \in \rhsfamily, \; \bvec{x}_0 \in \initialcond(f) \} $
    на сетке $ \{ t_n \}_{n=0}^N $ с функционалом качества $ \Phi $
    назовём
    \begin{equation}
        \label{eq:adaptation_method:adapted_numerical_method}
        M^\optimal = \argmin_{M \in \nmfamily} \sup_{f \in \rhsfamily} \sup_{\bvec{x}_0 \in \initialcond(f)}
        \Phi(\{ \bvec{x}_M^n(\bvec{x}_0) \}_{n=0}^N, \bvec{x}_f(\blankarg; \bvec{x}_0) )
    \end{equation}
\end{definition}

Предложенная процедура адаптации расширяет подход, рассмотренный в более ранних работах,
где для семейства линейных систем $ \dot{\bvec{x}} = A \cdot \bvec{x} $, $ A \in \linopset(\banachspace) $
производился поиск оптимального значения параметра $ \theta \in \reals $ тета-схемы
как в случае фиксированного $ A $~\cite{liniger1970efficient_integration_methods, lambert1991methods, berzins1992adaptive_theta_method},
так и в случае $ A \in \{ \lambda \identity \mid \lambda \in \reals \} $~\cite{liniger1969global_accuracy, johnson1988tunable_integration_method}.
Можно также показать, что общая процедура экспоненциальной подгонки, рассматриваемая,
например, в~\cite{hollevoet2013exponential_fitting}, является частным случаем адаптации:
требование точного воспроизведения полиномиальных и экспоненциальных решений
можно сформулировать в терминах минимизации разницы между численным и точным решением некоторой задачи Коши.

Важно отметить, что адаптацию можно проводить по одной системе, но результат применять к другой.
Например, интересующую нас задачу можно аппроксимировать более простой,
для которой известно аналитическое решение, и уже по этому решению подобрать оптимальную схему,
которая в дальнейшем будет использована для интегрирования исходного уравнения.
Более того, адаптацию имеет смысл проводить динамически, на каждом шаге интегрирования,
так как аппроксимация исходной системы может сильно меняться с течением времени.
Наконец, адаптация может быть использована для нахождения оптимального баланса
между устойчивостью численного метода и простотой поиска корней невязки,
что должно улучшить поведение численного решения при интегрировании жёстких во всех смыслах систем.

Приведём несколько дополнительных замечаний, подробнее раскрывающих особенности описанного метода:
\begin{enumerate}
    \item
        Результат адаптации всё ещё лежит в исходном семействе схем: $ M^\optimal \in \nmfamily $.
        Следовательно, грамотный выбор $ \nmfamily $ гарантирует хорошее поведение $ M^\optimal $
        на широком классе задач, несмотря на адаптацию к конкретному семейству задач Коши.

    \item
        Частным случаем является подбор численной схемы,
        дающей точное решение для выбранного множества задач:
        достаточно в качестве $ \Phi $ взять норму разности численного решения и проекции истинного решения на сетку.
        Тогда, если минимум достигается и равен нулю,
        численные решения, получаемые при помощи $ M^\optimal $, совпадают с точными на узлах выбранной сетки.
        Такие методы будем называть \emph{точно адаптированными}.

        Таким образом, предложенный подход обобщает идею, стоящую за экспоненциальными интеграторами
        и экспоненциальной адаптацией~\cite{liniger1970efficient_integration_methods, lambert1991methods, hollevoet2013exponential_fitting}.

    \item
        Если схема одношаговая, можно ограничиться $ N = 1 $,
        то есть подбирать схему для оптимизации качества на одном шаге интегрирования.
        В случае точной адаптации это полностью эквивалентно общему подходу.
\end{enumerate}


\section{Примеры использования в задачах малой размерности}
\label{section:methods:low_dimensional_examples}

В данном разделе предложенный метод будет применён к набору динамических систем малой размерности,
имеющих аналитическое решение либо всегда, либо при определённых условиях.
Будет рассмотрена линейная динамическая система,
уравнение логистического роста и движение материальной точки по круговой орбите.
Все три примера являются аппроксимациями более сложных систем,
что оправдывает их использование для подбора численной схемы.

\subsection{Одномерная линейная динамическая система}
\label{subsection:methods:one_dimensional_linear_system}

Пусть $ f \colon \reals \to \reals $ дифференцируема в некоторой окрестности $ x_0 $.
Тогда динамическую систему, заданную уравнением $ \dot x = f(x) $,
можно линеаризовать: $ \dot x \approx f(x_0) + \frac{\partial f}{\partial x}(x_0) \cdot (x - x_0) $.
Линеаризованный вариант уравнения далее можно использовать для адаптации некоторого выбранного семейства численных схем.
Результат адаптации потенциально может вести себя устойчивее и давать более точные численные решения,
так как линейная часть исходной системы будет интегрироваться с меньшей ошибкой.

Рассмотрим систему $ \dot x = a \, x + b $, $ a \in \complexes \setminus \{ 0 \} $,
эквивалентную линеаризованной.
Аналитическое решение соответствующей задачи Коши~--- $ x(t) = e^{a t} x_0 + (e^{a t} - 1) b / a $.
В качестве семейства численных методов возьмём тета-схему~\eqref{eq:linear_stability_theory:weighted_two_point}.
%
%\begin{equation}
%    \label{eq:one_dimensional_linear_system:one_dimensional_theta-method}
%    \frac{x^{n+1} - x^n}{\Delta t} = \theta f(x^{n+1}) + (1 - \theta) f(x^n), \qquad \theta \in [0;1]
%\end{equation}
%
Подберём $ \theta $ таким образом,
чтобы численное решение за один шаг $ \Delta t $ совпадало с аналитическим.
Так как схема одношаговая, а система автономная,
это гарантирует совпадение численного и аналитического решения на произвольном числе шагов.
Обозначив $ z = a \Delta t $, имеем
\[
    \frac{e^{a \Delta t} x_0 + (e^{a \Delta t} - 1) b / a - x_0}{\Delta t} = \theta a \cdot \left[ e^{a \Delta t} x_0 + (e^{a \Delta t} - 1) b / a \right] + (1 - \theta) a \cdot x_0 + b
\]
\[
    (e^{z} - 1)(x_0 + b / a) = \theta \cdot z (e^{z} - 1)(x_0 + b / a) + z \cdot x_0 + b \Delta t
\]
\[
    (e^{z} - 1) = \theta \cdot z (e^{z} - 1) + z
\]
%
\begin{equation}
    \label{eq:one_dimensional_linear_system:optimal_theta}
    \theta^\optimal(z) = \frac{1}{z} - \frac{1}{e^{z} - 1}
\end{equation}
%
Видно, что~\eqref{eq:one_dimensional_linear_system:optimal_theta} не зависит от $ b $;
это можно было бы учесть ранее, сделав замену $ x' = x - b/a $,
допустимую в рассматриваемом одномерном случае.
Тот же самый результат можно получить, приравняв функцию устойчивости тета-метода к экспоненте:
\[
    e^z = R_\theta(z) \defeq \frac{1 + (1 - \theta) z}{1 - \theta z}
\]
Полученное выражение совпадает с формулой, приведённой в более ранних работах по
экспоненциальной подгонке тета-схемы~\cite{liniger1970efficient_integration_methods, lambert1991methods, berzins1992adaptive_theta_method};
мы подробнее проанализируем его в секции~\ref{section:methods:exponential_fitting},
где будет рассматриваться аналогичная,
но многомерная задача.

Если правая часть дифференциального уравнения не является линейной,
значение $ a $ можно оценить либо по нескольким последовательным шагам численного интегрирования~\cite{berzins1992adaptive_theta_method}
(неявная линеаризация),
либо через дифференцирование правой части уравнения (явная линеаризация).

Вместо точной подгонки под фиксированное значение $ a \Delta t $
можно также рассмотреть семейство линейных правых частей,
соответствующих множеству $ a \Delta t \in [\underline{z}; \overline{z}] \subseteq \reals $.
Без ограничения общности будем считать $ b = 0 $.
Также считаем $ \theta \in [0;1] $.
В качестве функционала качества рассмотрим абсолютную ошибку за один шаг интегрирования,
поделённую на $ |x_0| $:
\[
    \Phi(\{ x_M^n \}_{n=0}^1; x(\blankarg; x_0)) = |x^1_M - x(\Delta t; x_0)| / |x_0| = |R_M(a \Delta t) - e^{a \Delta t}|
\]
%
\begin{equation}
    \label{eq:one_dimensional_linear_system:optimal_theta_for_stiff_systems}
    \theta^\optimal(\underline{z}, \overline{z}) = \argmin_{\theta \in [0;1]}
    \max_{z \in [\underline{z}; \overline{z}]} |R_\theta(a \Delta t) - e^{a \Delta t}|
\end{equation}
%
Максимум $ |R_\theta(z) - e^z| $ на отрезке $ [\underline{z}; \overline{z}] $ достигается либо в концах отрезка,
либо в стационарных точках, либо в точке разрыва.

Стационарные точки:
%
\begin{multline*}
    \frac{\partial}{\partial z} (R_\theta(z) - e^z) = \frac{1}{(\theta z - 1)^2} - e^z = 0 \quad \Longrightarrow \\
    \Longrightarrow \quad z_1 = 0, \;
    z_{2,3} = 2 W_n \left( \mp \frac{e^{-1 / (2 \theta)}}{2 \theta} \right) + \frac{1}{\theta},
\end{multline*}
%
где $ W_n $~--- \emph{$ W $-функция Ламберта}, $ n \in \{ -1, 0 \} $.
Точка разрыва второго рода (соответствует бесконечной ошибке численного решения): $ z_4 = 1/\theta $.

Поскольку все численные решения при $ z > z_4 $ меняют знак,
имеет смысл рассматривать только $ \theta \leqslant \max \{ 1, 1/\overline{z} \} $.
Отсюда следует, что не требуется исследовать и точку $ z_3 $,
так как при указанном ограничении на $ \theta $ имеем $ z_3 > z_4 > \overline{z} $.
Не требуется рассматривать и $ z_1 $, в которой ошибка равна нулю.

Заметим, что стационарная точка также характеризуется равенством
$ \theta = (1 \mp e^{-z/2}) / z $, где минус соответствует $ z_2 $.
Отсюда получаем значение ошибки в точке $ z_2 $:
\[
    |R_\theta(z_2) - e^{z_2}| = |1 + z_2 e^{z_2/2} - e^{z_2}| =
    \left|1 + \frac{z_2}{1 - \theta z_2} - \frac{1}{(1 - \theta z_2)^2} \right|
\]
Итоговое оптимальное значение $ \theta^\optimal(\underline{z}, \overline{z}) $
минимизирует максимальную из ошибок в $ \underline{z} $, $ \overline{z} $ и
$ z_2 $, если последняя лежит в $ [\underline{z}, \overline{z}] $.
В частности, если $ \overline{z} = 0 $ и $ \underline{z} \to -\infty $ (случай жёсткого спектра),
\[
    \argmin_\theta \max_{- \infty < z < 0} | e^z - R_\theta(z) | \approx 0.878 = \theta^\optimal(-\infty, 0),
\]
что совпадает со значением, полученным в работе~\cite{liniger1969global_accuracy}.

Значения $ \theta^\optimal(-\infty, \overline{z}) $ для различных $ \overline{z} $
приведены на рис.~\ref{fig:one_dimensional_linear_system:optimal_theta_for_stiff_systems}.
Из данного графика видно, что оптимальные $ \theta $ для линейных систем с быстро убывающими решениями тяготеют к единице;
в то же время, появление положительной части спектра почти сразу опускает оптимум ниже $ 1/2 $.
Также интересно наличие небольшой <<полочки>> в районе нуля,
на которой $ \theta^\optimal(-\infty; \overline{z}) = \theta^*(-\infty; 0) $.

\begin{figure}[ht!]
    \centering
    \small
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \captionsetup{aboveskip=-\baselineskip}
        \begin{gnuplot}[terminal=tikz, terminaloptions={color size 8.0cm,5.0cm fontscale 0.9}]
            load "./gnuplot/common.gp"

            file_name = "./data/fitted_theta_method/optimal_theta_5.0.csv" 
            set xrange [-5:5]

            load "./gnuplot/optimal_theta.gp"
        \end{gnuplot}
        \caption{$ z \in [-5; 5] $}
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \captionsetup{aboveskip=-\baselineskip}
        \begin{gnuplot}[terminal=tikz, terminaloptions={color size 8.0cm,5.0cm fontscale 0.9}]
            load "./gnuplot/common.gp"

            file_name = "./data/fitted_theta_method/optimal_theta_20.0.csv" 
            set xrange [-20:20]

            load "./gnuplot/optimal_theta.gp"
        \end{gnuplot}
        \caption{$ z \in [-20; 20] $}
    \end{subfigure}
    \caption{Зависимость оптимального значения
        $ \theta^\optimal(\underline{z};\overline{z}) $~\eqref{eq:one_dimensional_linear_system:optimal_theta_for_stiff_systems}
        от $ \overline{z} $ при $ \underline{z} \to -\infty $.
        Для сравнения также приведён график $ \theta^\optimal(z) $ из уравнения~\eqref{eq:one_dimensional_linear_system:optimal_theta}.}
    \label{fig:one_dimensional_linear_system:optimal_theta_for_stiff_systems}
\end{figure}

На рисунках~\ref{fig:one_dimensional_linear_system:Dahlquist_optimal_theta_method_1}
и \ref{fig:one_dimensional_linear_system:Dahlquist_optimal_theta_method_2}
показано поведение адаптированной к отрицательному спектру тета-схемы ($ \theta = \theta^\optimal(-\infty; 0) $)
в случае одномерного уравнения Далквиста.
Из графиком можно сделать вывод,
что результат адаптации является компромиссом между осциллирующим методом трапеций и <<инертным>> неявным методом Эйлера.

\begin{figure}[ht!]
    \centering
    \small
    \begin{gnuplot}[terminal=tikz, terminaloptions={color size 16.0cm,6.0cm fontscale 0.8}]
        load './gnuplot/common.gp'

        set style increment default
        set style data lines
        set xlabel  '$ t $'
        set xrange  [ 0 : 10 ] noreverse writeback
        set ylabel  '$ x(t) $' offset -1 #rotate by 0
        set yrange  [ * : * ] noreverse writeback

        set key width -16

        # Параметры.
        z = -1.5
        N = 5                    # Число точек.
        T = 9.0                  # Время интегрирования.
        lamb = z * (N - 1) / T   # Показатель экспоненты.

        load './gnuplot/Dahlquist.gp'

        set xtics 1
        set xzeroaxis lw 2

        plot Trapezoid using (times[$1]):(Trapezoid[$1]) with linespoints t 'метод трапеций' lw 2 ps 2, \
             BackwardEuler using (times[$1]):(BackwardEuler[$1]) with linespoints t 'неявный метод Эйлера' lw 2 ps 2, \
             ForwardEuler using (times[$1]):(ForwardEuler[$1]) with linespoints t 'явный метод Эйлера' lw 2 ps 2, \
             f(x) t 'точное решение' lw 4 lc 'black', \
             ThetaMethod using (times[$1]):(ThetaMethod[$1]) with linespoints t "тета-схема, $ \\theta^\\optimal(-\\infty, 0) $" lc "red" pt 4 lw 2 ps 2
    \end{gnuplot}
    \caption{Поведение тета-схемы, адаптированной к отрицательному спектру, при решении одномерного уравнения Далквиста ($ z = -1.5 $).}
    \label{fig:one_dimensional_linear_system:Dahlquist_optimal_theta_method_1}
\end{figure}

\begin{figure}
    \centering
    \small
    \begin{gnuplot}[terminal=tikz, terminaloptions={color size 16.0cm,6.0cm fontscale 0.8}]
        load './gnuplot/common.gp'

        set style increment default
        set style data lines
        set xlabel  '$ t $'
        set xrange  [ 0 : 10 ] noreverse writeback
        set ylabel  '$ x(t) $' offset -1 #rotate by 0
        set yrange  [ * : * ] noreverse writeback

        set key width -16

        # Параметры.
        z = -15.0
        N = 5                    # Число точек.
        T = 9 #6.75              # Время интегрирования.
        lamb = z * (N - 1) / T   # Показатель экспоненты.

        load './gnuplot/Dahlquist.gp'

        set xtics 1
        set xzeroaxis lw 2

        plot Trapezoid using (times[$1]):(Trapezoid[$1]) with linespoints t 'метод трапеций' lw 2 ps 2, \
             BackwardEuler using (times[$1]):(BackwardEuler[$1]) with linespoints t 'неявный метод Эйлера' lw 2 ps 2, \
             f(x) t 'точное решение' lw 3 lc 'black', \
             ThetaMethod using (times[$1]):(ThetaMethod[$1]) with linespoints t "тета-схема, $ \\theta^\\optimal(-\\infty, 0) $" lc "red" pt 4 lw 2 ps 2
    \end{gnuplot}
    \caption{Поведение тета-схемы, адаптированной к отрицательному спектру, при решении одномерного уравнения Далквиста ($ z = -15.0 $).}
    \label{fig:one_dimensional_linear_system:Dahlquist_optimal_theta_method_2}
\end{figure}

\FloatBarrier


\subsection{Логистическое уравнение}
\label{subsection:methods:logistic_differential_equation}

Рассмотрим логистическое уравнение или \emph{уравнение Ферхюльста}~\cite{verhulst1838logistic_equation, cramer2002origins_of_logistic_regression}:
\begin{equation}
    \label{eq:logistic_differential_equation:logistic_differential_equation}
    \frac{\partial x}{\partial t} = a \cdot x (1 - x / K),
\end{equation}
где $ a $~--- параметр роста, $ K $~--- параметр насыщения.
Данное уравнение моделирует геометрический рост в условиях ограниченных ресурсов,
а потому часто возникает в качестве предельного или частного случая в химических,
биологических, экологических и экономических моделях.
Адаптация численного метода к логистическому уравнению потенциально может повысить точность интегрирования систем,
в которых наблюдается взрывной рост, сменяемый насыщением.

Аналитическим решением~\eqref{eq:logistic_differential_equation:logistic_differential_equation}
является логистическая функция, также известная как сигмоида:
\begin{equation}
    \label{eq:logistic_differential_equation:logistic_function}
    x(t) = \frac{x_0 K e^{a t}}{K + x_0 (e^{a t} - 1)}
\end{equation}

Аналогично предыдущему разделу, точно адаптируем тета-метод~\eqref{eq:linear_stability_theory:weighted_two_point}
к данной задаче для конкретных значении $ x_0 $, $ a $ и $ K $.
%Без ограничения общности положим $ K = 1 $ (соответствует замене переменной $ x' = x / K $).
Один шаг тета-метода:
\[
    x(\Delta t) - x_0 = \Delta t \cdot \left[ \theta \cdot a x(\Delta t) (1 - x(\Delta t) / K) + (1 - \theta) \cdot a x_0 (1 - x_0 / K) \right]
\]
Заметим, что
\[
    x(t) (1 - x(t) / K) = x_0 (1 - x_0 / K) \frac{K^2 e^{a t}}{(K + x_0 (e^{a t} - 1))^2} = e^{-a t} x_0 (1 - x_0 / K) \frac{(x(t))^2}{x_0^2},
\]
\[
    x(t) - x_0 = \frac{x_0 (1 - x_0 / K) K (e^{a t} - 1)}{K + x_0 (e^{a t} - 1)} = (1 - e^{- a t}) x_0 (1 - x_0 / K) \frac{x(t)}{x_0}
\]
откуда
\[
    %\frac{K (e^{a \Delta t} - 1)}{K + x_0 (e^{a \Delta t} - 1)} =
    (1 - e^{a \Delta t}) \frac{x(\Delta t)}{x_0} =
    a \Delta t \left[ \theta \cdot \left( e^{- a \Delta t} \frac{(x(\Delta t))^2}{x_0^2}  - 1 \right) + 1 \right]
\]
Обозначим $ z = a \Delta t $, $ \beta = x(\Delta t) / x_0 $.
Тогда
\begin{equation}
    \label{eq:logistic_differential_equation:optimal_theta}
    \theta^\optimal(z, \beta) = \frac{\beta (1 - e^{-z}) / z - 1}{\beta^2 e^{-z} - 1}, \qquad \beta(z, x_0/K) = \left[ e^{-z} + \frac{x_0}{K} (1 - e^{-z}) \right]^{-1}
\end{equation}

На практике параметр $ K $ обычно не известен,
а значение $ a $ возможно оценить через линеаризацию правой части только
на начальном (экспоненциальный рост) и на конечном (насыщение) этапе.
Хорошим приближением $ \beta $ может являться отношение численного решения на новом шаге
к решению на текущем: $ \beta = x^{n+1} / x^n $.
Также отметим, что в предельном случае $ a \Delta t \to 0 $ зависимостью $ \theta^\optimal $ от $ z $ можно пренебречь:
\[
    \lim_{z \to 0} \theta^\optimal(z, \beta) = \frac{\beta - 1}{\beta^2 - 1} = \frac{1}{\beta + 1} \approx \frac{x^n}{x^{n+1} + x^{n}}
\]
Альтернативно, параметры $ a $ и $ K $ можно находить через подгонку логистической кривой
под значения численного решения на прошлых итерациях.


\subsection{Движение материальной точки по окружности}
\label{subsection:methods:circular_orbit}

В задачах небесной механики конические сечения часто служат
хорошей аппроксимацией траекторий движения небесных тел~\cite{landau2022mechanics}.
Адаптация численных методов для точного воспроизведения эллиптических, параболических и гиперболических траекторий
может позволить существенно увеличить шаг интегрирования систем,
точные решения которых слабо отклоняются от конических сечений.

В данном разделе будет рассмотрена существенно упрощенная задача адаптации.
Конкретно, общее семейство двухшаговых одностадийных схем,
определённое в уравнении~\eqref{eq:linear_stability_theory:weighted_two_point},
будет адаптировано под задачу движения материальной точки по окружности в поле центральной силы.

Уравнение, задающее рассматриваемую систему:
%
\begin{equation}
    \label{eq:circular_orbit:central_froce_field}
    \begin{dcases}
        \frac{d \vec{r}}{d t} &= \vec{v}, \\
        \frac{d \vec{v}}{d t} &= \vec{a},
    \end{dcases}
    \qquad
    \vec{a} = -a(r) \cdot \vec{r} / r,
    \qquad
    \frac{v(0)}{r^2(0)} = a(r(0)),
\end{equation}
%
где $ r = |\vec{r}| $, $ v = |\vec{v}| $ и начальные условия выбраны так,
чтобы движение происходило по окружности ($ r(t) = const $).
Так как траектория является плоской кривой,
без ограничения общности считаем задачу двумерной.
Точное решение:
%
\begin{equation}
    \label{eq:circular_orbit:central_froce_field_solution}
    \vec{r}(t) = W(\omega t) \cdot \vec{r}(0), \qquad \vec{v}(t) = W(\omega t) \cdot \vec{v}(0), \qquad \omega = a(r) / v
\end{equation}
%
\begin{equation}
    \label{eq:circular_orbit:rotation_matrix}
    W(\varphi) =
    \begin{pmatrix}
        \cos(\varphi) & -\sin(\varphi) \\
        \sin(\varphi) & \cos(\varphi)
    \end{pmatrix}
    \quad
    \textnormal{(матрица поворота на угол $ \varphi $)}
\end{equation}
%
Рассмотрим сначала динамику $ \vec{v}(t) $.
Приравнивая численное решение за один шаг к точному,
получаем уравнение
\begin{align}
    (W(\omega \Delta t) - \identity) \cdot \vec{v}^{\, n} &= \Delta t \left[\Theta \cdot \vec{a}^{\, n+1} + (\identity - \Theta) \cdot  \vec{a}^{\, n} \right] \\
                                            &= \Delta t \left[ \Theta W(\omega \Delta t) + (\identity - \Theta) \right] \cdot  \vec{a}^{\, n} \\
                                            &= \Delta t \left[ \Theta (W(\omega \Delta t) - \identity) + \identity \right] \cdot \frac{a(r)}{v} W(\pi / 2) \cdot \vec{v}^{\, n},
\end{align}
где было использовано равенство $ \vec{v} / v = W(\pi / 2) \cdot \vec{a} / a(r) $.
Обозначив $ \Delta \varphi = \Delta t \cdot a(r) / v $ и $ B = W(-\pi / 2) $, получаем
\[
    \Theta = \left[ \identity + (B \Delta \varphi)^{-1} (\identity - W(\Delta \varphi)) \right] (\identity - W(\Delta \varphi))^{-1} = (\identity - W(\Delta \varphi))^{-1} + (B \Delta \varphi)^{-1}
\]
Несложно заметить, что
\[
    B^{-1} = -B =
    \begin{pmatrix}
        0 & -1 \\
        1 & \phantom{-}0
    \end{pmatrix}
\]
\[
    (\identity - W(\Delta \varphi))^{-1} =
    \frac{1}{2}
    \begin{pmatrix}
        1 & \cot(\Delta \varphi / 2) \\
        -\cot(\Delta \varphi / 2) & 1
    \end{pmatrix}
\]
Тогда оптимальная весовая матрица задаётся уравнением
\begin{equation}
    \label{eq:circular_orbit:optimal_Theta}
    \Theta^\optimal(\Delta \varphi) =
    \begin{pmatrix}
        \frac{1}{2} & \frac{1}{2} \cot(\frac{\Delta \varphi}{2}) - \frac{1}{\Delta \varphi} \\
        \frac{1}{\Delta \varphi} - \frac{1}{2} \cot(\frac{\Delta \varphi}{2}) & \frac{1}{2}
    \end{pmatrix}
\end{equation}

\begin{remark}
    \label{remark:circular_orbit:weight_function_limit_at_zero}
    Разрыв весовой функции в $ \Delta \varphi = 0 $ устраним,
    причём пределом является матрица, соответствующая методу трапеций:
    \[
        \lim_{x \to 0} \frac{1}{2} \cot\left( \frac{x}{2} \right) - \frac{1}{x} = 0,
        \qquad
        \lim_{\Delta \varphi \to 0} \Theta^\optimal(\Delta \varphi) = \frac{1}{2} \identity
    \]
\end{remark}

Несложно показать, что та же самая матрица является оптимальной для интегрирования $ \dot{\vec{r}} = \vec{v} $,
так как $ \vec{r}(t) $ также вращается по окружности с угловой скоростью $ \omega = a(r) / v $.


\section{Многомерная экспоненциальная адаптация}
\label{section:methods:exponential_fitting}

В предыдущем разделе рассматривались примеры адаптации семейства двухшаговых одностадийных схем
к различным задачам малой размерности.
В настоящем разделе будет исследована точная адаптация к линейной системе произвольной размерности,
также называемая \emph{экспоненциальной адаптацией}~\cite{hollevoet2013exponential_fitting}.
В первом подразделе будет описан общий алгоритм экспоненциальной адаптации семейств линейных схем.
В последующих подразделах он будет применён к нескольким выбранным семействам методов Рунге-Кутты.


\subsection{Общий алгоритм экспоненциальной адаптации}
\label{subsection:exponential_fitting:general_exponential_fitting}

Можно показать, что точная адаптация к системе $ \dot{\bvec{x}} = A \cdot \bvec{x} + \bvec{b} $
эквивалентна точной адаптации к системе $ \dot{\bvec{x}} = A \cdot \bvec{x} $.
В случае невырожденного $ A $ это доказывается заменой $ \bvec{x} := \bvec{x} + A^{-1} \cdot \bvec{b} $.
Однако данный результат справедлив и в общем случае.

\begin{theorem}
    \label{theorem:general_exponential_fitting:exponential_fitting_equivalency}
    Пусть $ \banachspace $~--- банахово, $ A \in \linopset(\banachspace) $.
    Если линейный численный метод точно интегрирует систему $ \dot{\bvec{x}} = A \cdot \bvec{x} $
    и семейство систем $ \dot{\bvec{x}} = \bvec{b} $ для любых $ \bvec{b} \in \banachspace $ и с любыми начальными условиями,
    то он точно интегрирует неоднородную систему $ \dot{\bvec{x}} = A \cdot \bvec{x} + \bvec{b} $
    с любыми начальными условиями.
\end{theorem}

\begin{proof}
    Рассмотрим задачу Коши
    \[
        \begin{dcases}
            \frac{d \bvec{x}}{d t} = A \cdot \bvec{x} + \bvec{b} \\
            \bvec{x}(0) = \bvec{x}_0
        \end{dcases}
        %\quad \Longleftrightarrow \quad
        %\bvec{x}(t) = \exp(t A) \cdot \bvec{x}_0 + \varphi_1(t A) \cdot t \bvec{b}
    \]
    Пусть $ \mathcal{X} = \range A $.
    Разложим линейное пространство в прямую сумму: $ \banachspace = \mathcal{X} \oplus \mathcal{Y} $.
    Пусть $ \bvec{x}(t) = \bvec{x}^x(t) + \bvec{x}^y(t) $ и $ \bvec{b} = \bvec{b}^x + \bvec{b}^y $,
    где $ \bvec{x}^x(t), \; \bvec{b}^x \in \mathcal{X} $.
    Тогда $ \dot{\bvec{x}}^x = 0 + \bvec{b}^x $,
    что может быть точно проинтегрировано численным методом по условию.
    %из чего следует $ \bvec{x}^x(t) = \bvec{x}_0^x + t \bvec{b}^x $.
    %По предположению из условия теоремы,
    %динамика $ \bvec{x}^x(t) $ будет проинтегрирована численным методом точно.
    Рассмотрим произвольный вектор $ \bvec{a} $: $ A \cdot \bvec{a} = \bvec{b}^y $
    (существует по определению $ \bvec{b}^y $).
    Определим $ \bvec{y}(t) = \bvec{x}^y(t) + \bvec{a} $.
    Тогда $ \dot{\bvec{y}}(t) = A \cdot \bvec{y} $,
    что может быть точно проинтегрировано численным методом по условию.

    Поскольку используется линейный численный метод,
    и для разложения исходной задачи на две использовались только аффинные преобразования
    (проекции на $ \mathcal{X} $, $ \mathcal{Y} $, замена переменных $ \bvec{y}(t) = \bvec{x}^y(t) + \bvec{a} $),
    численное решение никак не изменится,
    если интегрировать исходную задачу напрямую.
    Отсюда следует, что рассматриваемая задача Коши будет проинтегрирована точно.
\end{proof}

Следует отметить, что требование точно интегрировать уравнение $ \dot{\bvec{x}} = const $
является довольно слабым, и ему изначально удовлетворяет большинство численных методов.
%Также важно понимать, что метод должен быть линейным для фиксированного $ A $ и шага интегрирования.

Теорема~\ref{theorem:general_exponential_fitting:exponential_fitting_equivalency}
позволяет проводить экспоненциальную адаптацию,
используя только проверочное уравнение Далквиста.
Как следствие, достаточным признаком точного интегрирования линейных неоднородных систем
является попросту равенство экспоненте функции устойчивости
и способность метода точно интегрировать константную правую часть.

\begin{corollary}
    \label{corollary:general_exponential_fitting:exponential_fitting_equivalency}
    Численный метод с функцией устойчивости $ R(z) $ точно адаптирован к семейству задач Коши
    $ \{ \dot{\bvec{x}} = A \cdot \bvec{x} + \bvec{b}, \; \bvec{x}(0) = \bvec{x}_0 \mid \bvec{x_0}, \bvec{b} \in \banachspace \} $
    для фиксированного $ A \in \linopset(\banachspace) $ на сетке $ \{ 0, \Delta t \} $,
    если он точно адаптирован к семейству задач Коши
    $ \{ \dot{\bvec{x}} = \bvec{b}, \; \bvec{x}(0) = \bvec{x}_0 \mid \bvec{x_0}, \bvec{b} \in \banachspace \} $
    на той же сетке и $ R(\Delta t \cdot A) = \exp(\Delta t \cdot A) $.
\end{corollary}

Следствие~\ref{corollary:general_exponential_fitting:exponential_fitting_equivalency}
особенно удобно тем, что для большинства семейств численных методов функция устойчивости известна.
В частности, для методов Рунге-Кутты, задаваемых таблицей Бутчера,
%
\begin{equation}
    \label{eq:general_exponential_fitting:runge-kutta}
    R(z) = 1 + z \mathrm{b}^T (\identity - z \mathrm{A})^{-1} \mathrm{e} =
    \frac{\det (\identity - z \mathrm{A} + z \mathrm{e} \mathrm{b}^T)}{\det(\identity - z \mathrm{A})},
\end{equation}
%
где $ \mathrm{A} $, $ \mathrm{b} $~--- соответствующие части таблицы Бутчера,
а $ \mathrm{e} $~--- вектор, состоящий из единиц.


\subsection{Взвешенный метод Эйлера}
\label{subsection:exponential_fitting:weighted_Euler}

Произведём экспоненциальную адаптацию двухшаговой одностадийной схемы~\eqref{eq:linear_stability_theory:weighted_two_point}.
Нетрудно проверить, что схема точно интегрирует константную правую часть при любых $ \Theta $.
Воспользуемся следствием~\ref{corollary:general_exponential_fitting:exponential_fitting_equivalency}.
Для краткости обозначим $ \Delta t \cdot A = z $.
\[
    (\identity - z \Theta)^{-1} (\identity + z (\identity - \Theta)) = \exp(z)
\]
Поскольку в уравнении помимо $ \Theta $ фигурируют только регулярные функции от $ z $,
его можно решать в комплексных переменных
(см.~\ref{definition:regular_function_operator:regular_function_operator}).
\[
    (1 + z) - z \Theta = e^z (1 - z \Theta)
\]
%
\begin{equation}
    \label{eq:weighted_Euler:optimal_parameters}
    \Theta^\optimal(z) = \frac{1}{z} - \frac{1}{e^z - 1},
    %\quad
    %z \in \complexes \setminus \{ 2 \pi i \cdot k \mid k \in \integers, k \neq 0 \}
\end{equation}
%
Полученное выражение функционально совпадает с оптимальным значением $ \theta^\optimal(z) $
из раздела~\ref{subsection:methods:one_dimensional_linear_system}
(формула~\eqref{eq:one_dimensional_linear_system:optimal_theta}).
Основное отличие: $ z $ теперь может быть матрицей.
%Отметим следующие свойства $ \Theta^\optimal(z) $:

\begin{remark}
    \label{remark:weighted_Euler:optimal_parameters_properties}
    Функция $ \Theta^\optimal(z) $, заданная уравнением~\eqref{eq:weighted_Euler:optimal_parameters}
    обладает следующими свойствами:
    \begin{enumerate}
        \item $ \Theta^\optimal(z) $ регулярна в $ \complexes \setminus \{ 2 \pi i \cdot k \mid k \in \integers, k \neq 0 \} $;
        \item $ \displaystyle \Theta^\optimal(z) = \frac{1}{2} - \frac{z}{12} + \frac{z^3}{720} + \Oclass(z^4) $
            в окрестности $ z = 0 $;
        \item $ \Theta^\optimal(\reals) \subseteq (0; 1) \subseteq \reals $.
            Как следствие, $ \Theta^\optimal(\Delta t \cdot A) \in \reals^{n \times n} $ для $ A \in \reals^{n \times n} $
            (теорема~\ref{theorem:regular_function_operator:real_valued_matrix_function}).
    \end{enumerate}
\end{remark}

На практике в качестве $ z $ следует брать $ \Delta t \cdot F(x) $,
где $ F $~--- матрица Якоби правой части интегрируемой системы или её аппроксимация.
Для простоты вычислений $ \Theta^\optimal(z) $ также можно брать только диагональ матрицы Якоби
или усредненный спектр (след матрицы, делённый на размерность).


\subsection{Дважды взвешенный метод Эйлера}
\label{subsection:exponential_fitting:double_weighted_Euler}

Рассмотрим следующее семейство двухстадийных методов Рунге-Кутты,
заданное таблицей Бутчера
\[
    \begin{array}{c|cc}
        0 & 0 & 0 \\
        1 & 1 - \alpha & \alpha \\
        \hline
         & 1 - \beta & \beta
    \end{array}
    \qquad
    \alpha, \beta \in \reals
\]
Функция устойчивости:
\[
    R(z) = \frac{1 + (1 - \alpha) z - (\alpha - \beta) z^2}{1 - \alpha z}
\]
Поскольку параметра теперь два,
можно осуществить двойную экспоненциальную адаптацию:
$ R(z) = \exp(z) $, $ R(x) = \exp(x) $.
Рассмотрим случай коммутирующих $ z $ и $ x $,
позволяющий решить уравнение в комплексных переменных:
%
\begin{equation}
    \label{eq:double_weighted_Euler:optimal_parameters}
    \begin{aligned}
        \alpha^\optimal(x,z) &= \frac{z^2 (e^x - 1 - x) - x^2 (e^z - 1 - z)}{x z( z (e^x - 1) - x (e^z - 1))} \\
        \beta^\optimal(x,z)  &= \frac{(x-z)(e^z - 1 - z)(e^x - 1 - x)}{x z (z(e^x - 1) - x (e^z - 1))}
    \end{aligned}
\end{equation}
%
\begin{remark}
    \label{remark:double_weighted_Euler:optimal_parameters_properties}
    Функции $ \alpha^\optimal(x,z) $ и $ \beta^\optimal(x, z) $,
    заданные уравнениями~\eqref{eq:double_weighted_Euler:optimal_parameters}
    обладают следующими свойствами:
    \begin{enumerate}
        \item $ \displaystyle \alpha^\optimal(x,z) = \frac{1}{3} - \frac{x + z}{36} + \Oclass(|x|^2 + |z|^2) $
            и $ \displaystyle \beta^\optimal(x,z)  = \frac{1}{2} + \frac{x + z}{6}  + \Oclass(|x|^2 + |z|^2) $
            в окрестности $ x = 0 $, $ z = 0 $;
        \item $ \displaystyle \lim_{x \to -\infty} \alpha^\optimal(x,z) =
            \lim_{x \to -\infty} \beta^\optimal(x,z) = \Theta^\optimal_{\eqref{eq:weighted_Euler:optimal_parameters}}(z) $,
            что делает схему, полученную в разделе~\ref{subsection:exponential_fitting:weighted_Euler},
            частным случаем данного метода.
    \end{enumerate}
\end{remark}


\subsection{Адаптированный двухстадийный SDIRK-метод}
\label{subsection:exponential_fitting:two_stage_SDIRK}

Рассмотрим следующее семейство двухстадийных SDIRK-методов Рунге-Кутты~\cite{franko1997SDIRK},
заданное таблицей Бутчера
\[
    \begin{array}{c|cc}
        \alpha & \alpha & 0 \\
        1      & 1 - \alpha & \alpha \\
        \hline
         & 1 - \alpha & \alpha
    \end{array}
    \qquad
    \alpha \in \reals
\]
Функция устойчивости:
\[
    R(z) = \frac{1 + (1 - 2 \alpha) z}{(1 - \alpha z)^2}
\]
Оптимальное значение параметра:
%
\begin{equation}
    \label{eq:two_stage_SDIRK:optimal_parameters}
    \alpha^\optimal(z) = \frac{1 - e^{-z}}{z} \pm e^{-z} \sqrt{\frac{1}{z^2} \left( e^z (z - 1) + 1 \right)}
\end{equation}

Полученная функция очень проблемная,
так как требует вычисления матричного корня,
в общем случае не определённого однозначно.
Однако можно показать, что $ \alpha^\optimal(z) $ регулярна в окрестности нуля,
и довольно точно аппроксимируется первыми двумя членами ряда Тейлора:
\[
    \alpha^\optimal(z) \approx 1 - \frac{\sqrt{2}}{2} + \left( \frac{\sqrt{2}}{3} - \frac{1}{2} \right) \cdot z
\]
Стоит отметить, что при $ \alpha = 1 - \sqrt{2} / 2 $ исходная численна схема является L"=устойчивой.


\section{Модифицированный метод Ньютона}
\label{section:methods:modified_Newton_iteration}

Как уже было сказано, одним из преимуществ адаптивных методов является баланс между устойчивостью
и простотой поиска корней невязки дискретизованного уравнения.
В некоторых задачах, однако, требуется повышенная численная устойчивость,
соответствующая наиболее неявным методам.
Как было указано в разделе~\ref{subsection:stiffness:nonlinear_stiffness},
использование таких методов напрямую может быть затруднено из-за паразитических корней.
Интересным кажется подход,
использующий информацию о корнях невязки адаптированной схемы
для поиска корней невязки исходного, неадаптированного метода.

Часто корни невязки дискретизованного уравнения $ \res(\bvec{x}) $ с матрицей Якоби $ \jac(\bvec{x}) $
ищутся методом Ньютона:
%
\begin{equation}
    \label{eq:modified_Newton_iteration:Newton_method}
    \bvec{x}_{m+1}^{n+1} = \bvec{x}_m^{n+1} - \jac^{-1}(\bvec{x}_m^{n+1}) \cdot \res(\bvec{x}_m^{n+1}),
\end{equation}
%
где $ m $~--- номер нелинейной итерации метода.
Если вместо точного значения матрицы Якоби используется аппроксимация или модифицированное значение,
метод называется \emph{квазиньютоновским}.

Руководствуясь соображениями о характере нелинейной жёсткости,
можно построить квазиньютоновский метод,
оптимизирующий невязку исходной, неадаптированной численной схемы
через итерации метода Ньютона с матрицей Якоби
%полученной дифференцированием невязки адаптированной численной схемы.
невязки адаптированного метода.
Неформально, такой выбор матрицы Якоби будет <<подталкивать>> итерации метода Ньютона в сторону
корней менее неявной схемы, то есть в сторону от паразитических корней.
